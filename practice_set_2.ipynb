{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f634180d",
   "metadata": {},
   "source": [
    "1) Problem statement.\n",
    "\"Trips & Travel.Com\" company wants to enable and establish a viable business model to expand the customer base. One of the ways to expand the customer base is to introduce a new offering of packages. Currently, there are 5 types of packages the company is offering * Basic, Standard, Deluxe, Super Deluxe, King. Looking at the data of the last year, we observed that 18% of the customers purchased the packages. However, the marketing cost was quite high because customers were contacted at random without looking at the available information. The company is now planning to launch a new product i.e. Wellness Tourism Package. Wellness Tourism is defined as Travel that allows the traveler to maintain, enhance or kick-start a healthy lifestyle, and support or increase one's sense of well-being. However, this time company wants to harness the available data of existing and potential customers to make the marketing expenditure more efficient.\n",
    "\n",
    "2) Content\n",
    "What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.\n",
    "\n",
    "Most important features that have an impact on Product taken (target): Designation, Passport, Tier City, Martial status, occupation.\n",
    "Customers with Designation as Executive should be the target customers for the company .\n",
    "Customers who have passport and are from tier 3 city and are single or unmarried, have large business such customers have higher chances of taking new package.\n",
    "Customers monthly income in range of 15000- 25000, and age range 15-30, prefer 5 star properties also have higher chances of taking new package based on EDA.\n",
    "\n",
    "\n",
    "3) Trips & Travel Pipeline\n",
    "Pipeline Flow:\n",
    "Executive Summary → Business Problem → Data Understanding → EDA → Preprocessing  → Model Training → Model Comparison → Threshold Tuning → Conclusions & Recommendations\n",
    "\n",
    "4) We need to analyze the customers' data and information to provide recommendations to the Policy Maker and Marketing Team and also build a model to predict the potential customer who is going to purchase the newly introduced travel package.\n",
    "\n",
    "5) Tasks to Solve :\n",
    "To predict which customer is more likely to purchase the newly introduced travel package\n",
    "Which variables are most significant.\n",
    "Which segment of customers should be targeted more.\n",
    "\n",
    "6) Models : 1. Logistic Regression 2.Naive Bayes 3. KNN 4.Decision Tree 5. Random Forest 6.XG Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db00e0f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ee93b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python -1.-1.-1)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/my lenovo files/Data_Science/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Travel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611b5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2f0c2",
   "metadata": {},
   "source": [
    "#Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58edd158",
   "metadata": {},
   "source": [
    "1. Handling Missing values\n",
    "2. Handling Duplicates\n",
    "3. Check data type\n",
    "4. Understand the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61401547",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are',df.shape[0],'rows')\n",
    "print('There are',df.shape[1],'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd48b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminate duplicates\n",
    "\n",
    "print('No.of duplicate rows:',df.duplicated().sum())\n",
    "df.loc[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ffc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b60175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking all the categories:TypeofContact,Occupation,Gender,ProductPitched,\n",
    "#MaritalStatus,Designation\n",
    "\n",
    "df[\"Gender\"].value_counts()\n",
    "#df['TypeofContact'].value_counts()\n",
    "#df['Occupation'].value_counts()\n",
    "#df['ProductPitched'].value_counts()\n",
    "#df['MaritalStatus'].value_counts()\n",
    "#df['Designation'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b447b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TypeofContact'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77214f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ProductPitched'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MaritalStatus'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Designation'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0935950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing values for gender and marital status\n",
    "\n",
    "df[\"Gender\"] = df[\"Gender\"].replace(\"Fe Male\",\"Female\")\n",
    "df[\"MaritalStatus\"] = df['MaritalStatus'].replace('Unmarried','Single')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2460583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MaritalStatus\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149416f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking missing values,features with nan values\n",
    "\n",
    "features_with_na=[features for features in df.columns if df[features].isnull().sum()>=1]\n",
    "for feature in features_with_na:\n",
    "    print(feature,np.round(df[feature].isnull().mean()*100,5), '% missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad64e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistics on numerical columns (null cols)\n",
    "df[features_with_na].select_dtypes(exclude='object').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2db662",
   "metadata": {},
   "source": [
    "Imputing Null values\n",
    "1. Impute Median value for Age column\n",
    "2. Impute Mode for Type of Contract\n",
    "3. Impute Median for Duration of Pitch\n",
    "4. Impute Mode for NumberofFollowup as it is Discrete feature\n",
    "5. Impute Mode for PreferredPropertyStar\n",
    "6. Impute Median for NumberofTrips\n",
    "7. Impute Mode for NumberOfChildrenVisiting\n",
    "8. Impute Median for MonthlyIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35e01f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#age \n",
    "\n",
    "df.Age.fillna(df.Age.median(),inplace=True)\n",
    "\n",
    "#Type of Contract\n",
    "\n",
    "df.TypeofContact.fillna(df.TypeofContact.mode()[0],inplace =  True)\n",
    "\n",
    "#Duration of Pitch\n",
    "\n",
    "df.DurationOfPitch.fillna(df.DurationOfPitch.median(),inplace=True)\n",
    "\n",
    "#NumberofFollowup\n",
    "\n",
    "df.NumberOfFollowups.fillna(df.NumberOfFollowups.mode()[0],inplace= True)\n",
    "\n",
    "#PreferredPropertyStar\n",
    "\n",
    "df.PreferredPropertyStar.fillna(df.PreferredPropertyStar.mode()[0],inplace=True)\n",
    "\n",
    "#NumberofTrips\n",
    "\n",
    "df.NumberOfTrips.fillna(df.NumberOfTrips.median(),inplace= True)\n",
    "\n",
    "#NumberOfChildrenVisiting\n",
    "\n",
    "df.NumberOfChildrenVisiting.fillna(df.NumberOfChildrenVisiting.mode()[0],inplace= True)\n",
    "\n",
    "#MonthlyIncome\n",
    "\n",
    "df.MonthlyIncome.fillna(df.MonthlyIncome.median() , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a710474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"CustomerID\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ff3b9",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6cfe0b",
   "metadata": {},
   "source": [
    "Feature Extraction,analysis and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns for feature\n",
    "\n",
    "df['Total_Visitors'] = df['NumberOfPersonVisiting']+df['NumberOfChildrenVisiting']\n",
    "df.drop(columns=['NumberOfPersonVisiting','NumberOfChildrenVisiting'],axis=1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65263a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get no. all the numeric features \n",
    "\n",
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "print('No.of Numerical features : ', len(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of categorical features\n",
    "\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "print(\"No.of Categorical Features :\", len(cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc51e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of Discrete features\n",
    "\n",
    "discrete_features = [ feature for feature in num_features if len(df[feature].unique())<= 25]\n",
    "print('Num of Discrete Features:', len(discrete_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da5d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [ feature for feature in num_features if feature not in discrete_features ]\n",
    "print ('No.of Continuous features:',len(continuous_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9cd1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate EDA for Categorical Features\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for col in cat_features:\n",
    "    plt.figure(figsize = (8,4))\n",
    "    sns.countplot(data=df,x=col)\n",
    "    plt.title(f\"Count Plot - {col}\")\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate EDA : Categorical vs Target ,helps to see which categories have higher conversion rates\n",
    "\n",
    "for col in cat_features:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.countplot(data=df , x=col,hue = 'ProdTaken')\n",
    "    plt.title(f\"{col} vs ProdTaken\")\n",
    "    plt.xticks(rotation =  45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate Analysis — Category vs Target (ProdTaken)\n",
    "for col in cat_features:\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plotnumber=1\n",
    "    if plotnumber<=15:\n",
    "        ax = plt.subplot(5,3,plotnumber)\n",
    "        sns.countplot(x=df[col],hue='ProdTaken',data=df,color='orange')\n",
    "        plt.xlabel(col)\n",
    "\n",
    "        plotnumber+=1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb795e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion Rate by Category (Most Important)\n",
    "\n",
    "#This reveals which category has the highest chance of purchasing the package\n",
    "\n",
    "results = {}\n",
    "\n",
    "for col in cat_features:\n",
    "    results[col] = df.groupby(col)['ProdTaken'].mean()\n",
    "\n",
    "# Convert to a nice dataframe\n",
    "conv_df = pd.concat(results).reset_index()\n",
    "conv_df.columns = ['Feature', 'Category', 'Conversion_Rate']\n",
    "\n",
    "conv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary Table (Counts + Conversion + Avg Income)\n",
    "\n",
    "for col in cat_features:\n",
    "    display(df.groupby(col).agg(Count=('ProdTaken','count'),ConversionRate=('ProdTaken','mean'),AvgIncome=('MonthlyIncome','mean'))\n",
    "            .sort_values('ConversionRate',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Association with Target (Cramér’s V)\n",
    "#Measures the strength of relationship between categorical features and the target.\n",
    "\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "for col in cat_features:\n",
    "    print(col, \":\", cramers_v(df[col], df['ProdTaken']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5155a1",
   "metadata": {},
   "source": [
    "Analysing Features and target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abf02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(['ProdTaken'],axis=1)\n",
    "y = df[\"ProdTaken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cf368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714406c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abfeb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cbfb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dist = df['ProdTaken'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,5))\n",
    "\n",
    "barplot = plt.bar(target_dist.index, target_dist, color = 'lightgreen', alpha = 0.8)\n",
    "barplot[1].set_color('darkred')\n",
    "\n",
    "ax.set_title('Target Distribution')\n",
    "ax.annotate(\"percentage of Taken Prod : {}%\".format(df['ProdTaken'].sum() / len(df['ProdTaken'])),\n",
    "              xy=(0, 0),xycoords='axes fraction', \n",
    "              xytext=(0,-50), textcoords='offset points',\n",
    "              va=\"top\", ha=\"left\", color='grey',\n",
    "              bbox=dict(boxstyle='round', fc=\"w\", ec='w'))\n",
    "\n",
    "plt.xlabel('Target', fontsize = 12, weight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d47f7a2",
   "metadata": {},
   "source": [
    "RESAMPLING : A widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and / or adding more examples from the minority class (over-sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class = df['ProdTaken'].value_counts()\n",
    "\n",
    "count_class_0 = count_class.get(0, 0)\n",
    "count_class_1 = count_class.get(1, 0)\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = df[df['ProdTaken'] == 0]\n",
    "df_class_1 = df[df['ProdTaken'] == 1]\n",
    "\n",
    "print(\"Not Taken:\", count_class_0)\n",
    "print(\"Taken:\", count_class_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check real values inside the column\n",
    "print(df['ProdTaken'].unique())\n",
    "print(df['ProdTaken'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0_under = df_class_0.sample(count_class_1,random_state=42)\n",
    "df_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_under['ProdTaken'].value_counts())\n",
    "\n",
    "df_under['ProdTaken'].value_counts().plot(kind='bar', title='Count (target)');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e10993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "trainset,testset = train_test_split(df_under , test_size = 0.2,random_state=42)\n",
    "\n",
    "# --- Create EXACTLY 2 subplots ---\n",
    "fig,ax = plt.subplots(1,2,figsize = (10,5))\n",
    "\n",
    "# --- Train set plot ---\n",
    "sns.countplot(x='ProdTaken' , data = trainset,ax=ax[0],palette=\"Set3\") \n",
    "ax[0].set_title('Train_Set_Distribution')\n",
    "\n",
    "# --- Test set plot ---\n",
    "sns.countplot(x = 'ProdTaken' , data = testset,ax=ax[1],palette=\"Set2\")\n",
    "ax[1].set_title('Test_Set_Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trainset.drop(['ProdTaken'],axis=1)\n",
    "y_train = trainset['ProdTaken']\n",
    "X_test = testset.drop(['ProdTaken'],axis=1)\n",
    "y_test = testset['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b050f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train_class_distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nTest_class_distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a6c82",
   "metadata": {},
   "source": [
    "Models Creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaeb669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aaec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "\n",
    "# the code didnot work as standard scaler is for numerical data and I am using categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c41621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "\n",
    "cat_features = X_train.select_dtypes(include = \"object\").columns\n",
    "num_features = X_train.select_dtypes(exclude = \"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer =  StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop= 'first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\",oh_transformer,cat_features),\n",
    "         (\"StandardScaler\", numeric_transformer,num_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabbfd6a",
   "metadata": {},
   "source": [
    "# MODEL CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa4547c",
   "metadata": {},
   "source": [
    "You now need to attach a ML model (Logistic Regression, Random Forest, XGBoost, etc.) to the preprocessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aba8bc",
   "metadata": {},
   "source": [
    "--> Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = Pipeline ( \n",
    "    steps =  [\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"classifier\",LogisticRegression(max_iter=1000))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ec390",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead261f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17658223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the Model on Training Data\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f13992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "\n",
    "y_pred =model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd551ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the Logistic regression model \n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='d',cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd5472",
   "metadata": {},
   "source": [
    "--> Decision Tree, Random Forest,KNN,Naive Baiyes ,XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a89e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Model Dictionary\n",
    "\n",
    "models = {\n",
    "    \"Decision Tree\" : DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\" : RandomForestClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"NaiveBaiyes\": GaussianNB(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric = 'logloss',random_state =42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0907312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Function to Train + Evaluate Model\n",
    "def train_and_evaluate(model, model_name):\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    print(f\"\\n==================== {model_name} ====================\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Confusion Matrix Heatmap\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f91bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    train_and_evaluate(model, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c9481",
   "metadata": {},
   "source": [
    "Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97862f2b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f29e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve \n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Use pipeline\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    if hasattr(pipe.named_steps['classifier'], \"predict_proba\"):\n",
    "        y_pred_prob = pipe.predict_proba(X_test)[:,1]\n",
    "    else:  # For models like KNN or NB without predict_proba\n",
    "        y_pred_prob = pipe.predict(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.3f})\")\n",
    "\n",
    "plt.plot([0,1],[0,1],'--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision Recall Curve \n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    if hasattr(pipe.named_steps['classifier'], \"predict_proba\"):\n",
    "        y_pred_prob = pipe.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        y_pred_prob = pipe.predict(X_test)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "    plt.plot(recall, precision, label=name)\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision–Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Comparison (Accuracy)\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    accuracy_list.append({\"Model\": name, \"Accuracy\": accuracy_score(y_test, y_pred)})\n",
    "\n",
    "acc_df = pd.DataFrame(accuracy_list)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=\"Accuracy\", y=\"Model\", data=acc_df, palette=\"Set2\")\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.xlim(0,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ffe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the results \n",
    "\n",
    "accuracy_list = []\n",
    "roc_auc_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # ROC AUC\n",
    "    if hasattr(pipe.named_steps['classifier'], \"predict_proba\"):\n",
    "        y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "        roc_auc_score_val = auc(*roc_curve(y_test, y_prob)[:2])\n",
    "    else:\n",
    "        y_prob = pipe.predict(X_test)\n",
    "        roc_auc_score_val = auc(*roc_curve(y_test, y_prob)[:2])\n",
    "    \n",
    "    accuracy_list.append({\"Model\": name, \"Accuracy\": acc, \"ROC_AUC\": roc_auc_score_val})\n",
    "\n",
    "results_df = pd.DataFrame(accuracy_list).sort_values(by=\"ROC_AUC\", ascending=False)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57be1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance (for Tree-Based Models)\n",
    "\n",
    "tree_models = [\"Decision Tree\", \"Random Forest\", \"XGBoost\"]\n",
    "\n",
    "for name in tree_models:\n",
    "    model = models[name]\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Get feature names after one-hot encoding\n",
    "    cat_features_ohe = pipe.named_steps['preprocessor'].named_transformers_['OneHotEncoder'].get_feature_names_out(cat_features)\n",
    "    all_features = np.concatenate([cat_features_ohe, num_features])\n",
    "    \n",
    "    importances = pipe.named_steps['classifier'].feature_importances_\n",
    "    feat_imp = pd.Series(importances, index=all_features).sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    feat_imp[:15].plot(kind='barh')\n",
    "    plt.title(f\"Top 15 Feature Importances - {name}\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7af64",
   "metadata": {},
   "source": [
    "Threshold Tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "for name, model in models.items():\n",
    "    print('---------------------------------')\n",
    "    print(name)\n",
    "    \n",
    "    # Create a pipeline: preprocessing + classifier\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),  # handles one-hot + scaling\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    if hasattr(pipe.named_steps['classifier'], \"predict_proba\"):\n",
    "        y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        # For models that don't support predict_proba\n",
    "        y_prob = pipe.predict(X_test)\n",
    "    \n",
    "    # Apply threshold\n",
    "    y_pred_new = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_new))\n",
    "    print(classification_report(y_test, y_pred_new))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred_new)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"{name} - Confusion Matrix (Threshold={threshold})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3dd683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold tuning\n",
    "\n",
    "#fitting pipeline\n",
    "\n",
    "#getting predicted probabilities\n",
    "\n",
    "# Probability for class 1 ('ProdTaken=1')\n",
    "y_prob = pipe.predict_proba(X_test)[:,1]  # [:,1] selects the positive class\n",
    "\n",
    "#Applying different thresholds\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "thresholds = np.arange(0.1, 0.9, 0.1)  # test thresholds from 0.1 to 0.8\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_prob >= t).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred_t)\n",
    "    precision = precision_score(y_test, y_pred_t)\n",
    "    recall = recall_score(y_test, y_pred_t)\n",
    "    print(f\"Threshold={t:.1f} -> Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another method for threshold comparison\n",
    "#y_prob = pipe.predict_proba(X_test)[:,1]  # [:,1] selects the positive class\n",
    "#thresholds = [0.3,0.4,0.5,0.6,0.7,0.8]\n",
    "#best_t = 0.5\n",
    "#best_acc = 0\n",
    "##for t in thresholds:\n",
    "#    y_pred = (y_prob >= t).astype(int)\n",
    " #   acc = accuracy_score(y_test, y_pred)\n",
    "  #  if acc > best_acc:\n",
    "   #     best_acc=acc\n",
    "    #    best_t=t\n",
    "\n",
    "#print('Accuracy on test set :',round(best_acc*100),\"%\")\n",
    "#print('Best threshold :',best_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct Threshold Tuning Code (With F1 Score)\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "thresholds = [0.3,0.4,0.5,0.6,0.7,0.8]\n",
    "best_t = 0.3\n",
    "best_f1 = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (y_prob >= t).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Threshold={t} → F1={f1:.4f}\")\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_t = t\n",
    "\n",
    "print(\"\\nBest F1:\", best_f1)\n",
    "print(\"Best Threshold:\", best_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab70df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", XGBClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_prob = best_model.predict_proba(X_test)[:,1]   # probability of class 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b66b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "\n",
    "results = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_prob >= t).astype(int)\n",
    "    results.append([\n",
    "        t,\n",
    "        accuracy_score(y_test, y_pred_t),\n",
    "        precision_score(y_test, y_pred_t),\n",
    "        recall_score(y_test, y_pred_t),\n",
    "        f1_score(y_test, y_pred_t)\n",
    "    ])\n",
    "\n",
    "threshold_df = pd.DataFrame(results, columns=[\"Threshold\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "threshold_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec64b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(threshold_df[\"Threshold\"], threshold_df[\"Precision\"], label=\"Precision\")\n",
    "plt.plot(threshold_df[\"Threshold\"], threshold_df[\"Recall\"], label=\"Recall\")\n",
    "plt.plot(threshold_df[\"Threshold\"], threshold_df[\"F1\"], label=\"F1 Score\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Threshold Tuning Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eafe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_t = threshold_df.loc[threshold_df['Recall'].idxmax(), 'Threshold']\n",
    "best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best = (y_prob >= best_t).astype(int)\n",
    "\n",
    "print(\"Best Threshold:\", best_t)\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_best), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_t:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING THE MODELS\n",
    "\n",
    "# save the modelS \n",
    "\n",
    "# we dont have to retrain the model every time\n",
    "# the model can be used in production application\n",
    "# it helps in sharing and deployement\n",
    "# pickle (.pkl format)\n",
    "# joblib (.joblib format)\n",
    "\n",
    "\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be23f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'classification_models.sav'\n",
    "pickle.dump(models, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d42b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd55d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python -1.-1.-1)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/my lenovo files/Data_Science/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee77777",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python -1.-1.-1)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/my lenovo files/Data_Science/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pip version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85e3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
